mpdo[1,,]
mpdoM= matrix(mpdo, ncol = B)
View(mpdoM)
testA = matrix(mpdoM[1,], nrow = 1)
for (j in 1:no){
for (i in 1:no2){
testA = rbind(testA, matrix(mpdoM[j + i*no - no,], nrow = 1))
}
}
array(testA[-1,], c(no*no2,1,B))
mpdoA = array(testA[-1,], c(no*no2,1,B))
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no),], no*no2,B*no*ni)
View(mpdoA_temp)
mpdoA_fixed = aperm(array(matrix(t(mpdoA_temp), nrow=B), c(no*no2,B*ni, no)), c(2,1,3))
mpdoA_fixed = aperm(array(matrix(t(mpdoA_temp), nrow=B), c(no*no2,B*ni, no*no2)), c(2,1,3))
View(mpdoA)
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no*no2),], no*no2,B*no*ni*no2)
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no),], no*no2,B*no*ni)
mpdoA_fixed = aperm(array(matrix(t(mpdoA_temp), nrow=B), c(no*no2,B*ni, no)), c(2,1,3))
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no*no2),], no*no2,B*no*ni*no2)
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no),], no*no2,B*no*ni)
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no),], no*no2,B*no*ni)
View(mpdoA_temp)
matrix(t(mpdoA_temp), nrow=B)
array(matrix(t(mpdoA_temp), nrow=B), c(B*ni,no*no2, no))
array(matrix(t(mpdoA_temp), nrow=B), c(no*no2,B*ni, no))
matrix(mpdoA_temp, nrow=B)
matrix(t(mpdoA_temp), nrow=B)
array(matrix(t(mpdoA_temp), nrow=B), c(no*no2,B*ni, no))
array(matrix(t(mpdoA_temp), nrow=B), c(no*ni,B, no*no2))
array(matrix(t(mpdoA_temp), nrow=B), c(B*ni,no*no2, no))
array(matrix(t(mpdoA_temp), nrow=B), c(B*ni,no, no*no2))
aperm(array(matrix(t(mpdoA_temp), nrow=B), c(B*ni,no, no*no2)), c(2,1,3))
array(matrix(t(mpdoA_temp), nrow=B), c(no,B*ni, no*no2))
aperm(array(matrix(t(mpdoA_temp), nrow=B), c(no,B*ni, no*no2)), c(2,1,3))
array(aperm(array(matrix(t(mpdoA_temp), nrow=B), c(no,B*ni, no*no2)), c(2,1,3)), c(B*ni, no*no2, no))
mpdoM = matrix(mpdo, ncol = B)
testA = matrix(mpdoM[1,], nrow = 1)
for (j in 1:no){
for (i in 1:no2){
testA = rbind(testA, matrix(mpdoM[j + i*no - no,], nrow = 1))
}
}
mpdoA = array(testA[-1,], c(no*no2,1,B))
mpdoA_temp = matrix(mpdoA[, rep(1:ncol(mpdoA), each = ni*no),], no*no2,B*no*ni)
mpdoA_fixed = array(aperm(array(matrix(t(mpdoA_temp), nrow=B), c(no,B*ni, no*no2)), c(2,1,3)), c(B*ni, no*no2, no))
load_all()
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
View(multiplier)
View(CdgodgiA_fixed)
View(Cdgodgi)
CdgodgiA_fixed[1,1,2]
CdgodgiA_fixed[1,46,2]
all(CdgodgiA_moving[,,1]==CdgodgiA_moving[,,2])
all(mpdiA_moving[,,1]==mpdiA_moving[,,2])
View(mpdiA_moving)
View(mpdoA_moving)
all(mpdoA_moving[,,1]==mpdoA_moving[,,2])
View(mpdiA_fixed)
mpdiA_fixed[,,2]
View(mpdi)
mpdiA_fixed[,,45]
View(mpdoA_fixed)
keep = mpdo
View(mpdo)
sum = array(matrix(Cwdowdowwdi2, nrow = B*ni*no), c(B*ni*no, no2, no))
sum_Cwdowdowwdi2 = array(apply(sum, 3, rowSums), c(B*ni, no, no))
sumtest = array(matrix(test, nrow = B*ni*no), c(B*ni*no, no2, no))
sum_test=array(apply(sumtest, 3, rowSums), c(B*ni, no, no))
View(sumtest)
View(sum_Cwdowdowwdi2)
View(sum_test)
mddgi <- fcMeanDlayer2array(mpdi2w, mdgo, sum_test, ni, no, B)
load_all()
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
View(mddgi)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
yp = out_runBatchDerivative[[1]]
Syp = out_runBatchDerivative[[2]]
dyp = out_runBatchDerivative[[3]]
ddyp_after = out_runBatchDerivative[[4]]
points(xtest, ddyp_after, col = "magenta", pch = 5)
plot(x = xtest, y = dytest, xlab = "x", type = "lines", ylim =c(-5,5))
points(xtest, ddyp_after, col = "magenta", pch = 5)
points(xtest, dyp, col = "blue", pch = 5)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
ddyp_3hl = out_runBatchDerivative[[4]]
ddyp_3hl = out_runBatchDerivative[[4]]
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
View(ddyp_3hl)
View(ddyp_3hl)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
ddyp_2hl = out_runBatchDerivative[[4]]
points(xtest, ddyp_2hl, col = "green", pch = 5)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
ddyp_2hl_run2 = out_runBatchDerivative[[4]]
points(xtest, ddyp_2hl_run2, col = "orange", pch = 5)
set.seed(100)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
set.seed(100)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
ddyp_2hl_run3 = out_runBatchDerivative[[4]]
points(xtest, ddyp_2hl_run3, col = "red", pch = 5)
plot(x = xtest, y = dytest, xlab = "x", type = "lines", ylim =c(-5,5))
points(xtest, ddyp_3hl, col = "magenta", pch = 5)
points(xtest, ddyp_2hl_run3, col = "red", pch = 5)
points(xtest, ddyp_2hl_run2, col = "orange", pch = 5)
document()
load_all()
set.seed(100)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1,0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1,1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
compare_opt_fct = cbind(ddyp_2hl_run3, out_runBatchDerivative[[4]])
View(compare_opt_fct)
diff = ddyp_2hl_run3-out_runBatchDerivative[[4]]
View(diff)
all(ddyp_2hl_run3 = out_runBatchDerivative[[4]])
all(compare_opt_fct[,1] = compare_opt_fct[,2])
all(compare_opt_fct[,1] == compare_opt_fct[,2])
set.seed(100)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
ddyp_3hl_before_opt = out_runBatchDerivative[[4]]
points(xtest, ddyp_3hl_before_opt, col = "black", pch = 5)
plot(x = xtest, y = dytest, xlab = "x", type = "lines", ylim =c(-5,5))
points(xtest, ddyp_3hl, col = "magenta", pch = 5)
points(xtest, ddyp_3hl_before_opt, col = "black", pch = 5)
plot(x = xtest, y = dytest, xlab = "x", type = "lines", ylim =c(-5,5))
points(xtest, ddyp_2hl_run2, col = "orange", pch = 5)
points(xtest, ddyp_2hl_run3, col = "red", pch = 5)
points(xtest, ddyp_2hl, col = "green", pch = 5)
set.seed(100)
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
View(combinations_matrix)
set.seed(100)
# 2 hidden layers
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
force(dlayer)
load_all()
set.seed(100)
# 2 hidden layers
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
set.seed(100)
# 2 hidden layers
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
plot(x = xtest, y = dytest, xlab = "x", type = "lines", ylim =c(-5,5))
abline(h=2, col = "blue")
points(xtest, ddyp_3hl, col = "magenta", pch = 5)
points(xtest, ddyp_2hl_run3, col = "red", pch = 5)
plot(x = xtest, y = dytest, xlab = "x", type = "lines", ylim =c(-5,5))
abline(h=2, col = "blue")
points(xtest, ddyp_3hl, col = "magenta", pch = 5)
points(xtest, ddyp_2hl_run3, col = "green", pch = 5)
points(xtest, dyp, col = "blue", pch = 5)
load_all()
set.seed(100)
# 3 hidden layers
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 100, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
force(Cdgodgi)
force(mpdi)
all(CdgodgiA_moving[,,1] = CdgodgiA_moving[,,1000])
all(CdgodgiA_moving[,,1] == CdgodgiA_moving[,,1000])
all(Cdgodgi == CdgodgiA_moving[,,1000])
all(mpdiA_moving[,,1] == mpdiiA_moving[,,1000])
all(mpdiA_moving[,,1] == mpdiA_moving[,,1000])
View(mpdiA_moving)
Q
set.seed(100)
# 3 hidden layers
NN <- list(
"task" = "regression",
"nx" = nx, # Number of input covariates
"ny" = ny, # Number of output responses
"batchSize" = 5, # Batch size
"repBatchSize" = 1,
"layer" = c(1, 1, 1, 1, 1), # 1: fully connected
"nodes" = c(nx, 45, 45, 45, ny), # Number of nodes for each layer
"actFunIdx" = c(0, 1, 1, 1, 0), # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
"actBound" = c(1, 1, 1, 1, 1), # Activation function for output layer {'linear', 'tanh','sigm','cdf','relu'}
"sx" = NULL, # Input standard deviation
"sv" = 0.05, # Observations standard deviation
"noiseType" = "none",
"initParamType" = "Xavier", # Parameter initialization
"maxEpoch" = 10, # maximal number of learning epoch
"numSplits" = 20, # number of splits
"collectDev" = 2, # calculate derivative
"convariateEstm" = 1,
"trainMode" = 1
)
out_runBatchDerivative = runBatchDerivative(NN, xtrain, ytrain, xtest, ytest)
View(mpdiA_mvmpdiA_moving[,,1]])
View(mpdiA_mpdiA_moving[,,1]])
View(mpdiA_mpdiA_moving[,,1])
View(mpdiA_moving[,,1])
